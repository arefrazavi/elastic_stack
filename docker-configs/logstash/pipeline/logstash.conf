# Sources from which data is to be sent to logstash using different plugins.
input {
    # Get data from a file
    file {
        path => "/usr/share/logstash/pipeline/access.log"
        start_position => "beginning"
    }
}

# How to exract and structure (parse and filter) data.
filter {
    # Use the built-in Apache log filter to extract the fields in raw message.
    grok {
        match => {"message" => "%{COMBINEDAPACHELOG}"}
    }
    date {
        match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
    }
}

# Destinations to which the structured data is to be sent from logstash.
output {
    # Send to elasticsearch
    elasticsearch {
        hosts => "elasticsearch:9200"
    }
    # Send to console
    stdout {
        codec => rubydebug
    }
}